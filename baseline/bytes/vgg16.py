import torch
import torch.nn as nn
import torch.utils.data

from bytes.create_data.generate_dataset import get_dataset


class VGG16(nn.Module):
    def __init__(self):
        super().__init__()

        self.input = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU(),
            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU()
        )
        self.block1 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU(),
            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU()
        )
        self.block2 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU(),
            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU(),
            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU()
        )
        self.block3 = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU()
        )
        self.block4 = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU()
        )
        self.fc = nn.Linear(512, 9)

    def forward(self, x):
        output = self.input(x)
        output = nn.MaxPool2d(kernel_size=3)(output)
        output = self.block1(output)
        output = nn.MaxPool2d(kernel_size=3)(output)
        output = self.block2(output)
        output = nn.MaxPool2d(kernel_size=3)(output)
        output = self.block3(output)
        output = nn.MaxPool2d(kernel_size=3)(output)
        output = self.block4(output)
        output = nn.MaxPool2d(kernel_size=3)(output)
        output = output.view(output.size(0), -1)
        output = self.fc(output)

        return output


def train_model(model_path, epoch):
    """
    Train the specified model.
    :param model_path: The path to save model.
    :param epoch: Number of iterations to train model.
    :return: Trained model.
    """
    train_path = input("Please input the path of training data: ")
    if train_path[-1] != '/':
        train_path += '/'
    test_path = input("Please input the path of test data: ")
    if test_path[-1] != '/':
        test_path += '/'

    # get training Dataset
    dataset = get_dataset(train_path)
    # get training DataLoader
    train_loader = torch.utils.data.dataloader.DataLoader(dataset, batch_size=20)

    # get test Dataset
    dataset = get_dataset(test_path)
    # get test DataLoader
    test_loader = torch.utils.data.dataloader.DataLoader(dataset, batch_size=8)

    criterion = nn.CrossEntropyLoss().cuda()

    model = VGG16().cuda()
    # Kaiming He initialization
    for m in model.modules():
        if isinstance(m, (nn.Conv2d, nn.Linear)):
            nn.init.kaiming_normal_(m.weight, mode='fan_in')

    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)

    best_accuracy = 0.0

    step = 0

    for i in range(epoch):
        print("epoch:", i)
        model.train()
        for j, data in enumerate(train_loader):
            x, y = data
            x = x.cuda()
            y = y.cuda()

            x_var = torch.autograd.Variable(x)
            y_var = torch.autograd.Variable(y.long())

            prediction = model(x_var)

            loss = criterion(prediction, y_var)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # save loss and epoch
            step += 1

        print('--------Validation--------')
        correct = torch.zeros(1).squeeze().cuda()
        total = torch.zeros(1).squeeze().cuda()

        model.eval()
        for j, data in enumerate(test_loader):
            x, y = data

            x = x.cuda()
            y = y.cuda()

            output = model(x)

            prediction = torch.argmax(output, 1)

            correct += (prediction == y.long()).sum().float()
            total += len(y)

        accuracy = (correct / total).cpu().item()
        print(accuracy)
        if accuracy > best_accuracy:
            # save best model
            torch.save(model, "".join(model_path.split('.')[:-1]) + "_best.pth")
            best_accuracy = accuracy

    torch.save(model, model_path)


train_model('vgg16.pth', 20)
