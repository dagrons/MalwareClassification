import torch.nn as nn


class BasicBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride):
        super().__init__()

        self.residual_function = nn.Sequential(
            nn.BatchNorm2d(in_channels),
            nn.LeakyReLU(),
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.LeakyReLU(),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)
        )

        self.shortcut = nn.Sequential()

        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.BatchNorm2d(in_channels),
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)
            )

    def forward(self, x):
        return self.residual_function(x) + self.shortcut(x)


class ResNet(nn.Module):
    def __init__(self, num_block, num_classes=9):
        super().__init__()

        self.in_channels = 32

        self.conv_input = nn.Sequential(
            nn.BatchNorm2d(3),
            nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=False),
            nn.LeakyReLU()
        )

        self.conv_block1 = self.generate_layer(32, num_block[0], 1)

        self.conv_block2 = self.generate_layer(32, num_block[1], 2)

        self.conv_block3 = self.generate_layer(64, num_block[2], 2)

        self.conv_block4 = self.generate_layer(64, num_block[3], 2)

        self.avg_pool = nn.AvgPool2d((2, 2))

        self.fc = nn.Linear(16384, num_classes)

    def generate_layer(self, out_channels, num_block, stride):
        """
        Generate ResNet layers. The stride of first block is could be 1 or 2, the others would always be 1.
        :param out_channels: output channels of this layer
        :param num_block: the number of blocks per layer
        :param stride: the stride of the first block
        :return: a ResNet layer
        """
        strides = [stride] + [1] * (num_block - 1)
        layers = []
        for stride in strides:
            layers.append(BasicBlock(self.in_channels, out_channels, stride))
            self.in_channels = out_channels

        return nn.Sequential(*layers)

    def forward(self, x):
        output = self.conv_input(x)
        output = self.conv_block1(output)
        output = self.conv_block2(output)
        output = self.conv_block3(output)
        output = self.conv_block4(output)
        output = self.avg_pool(output)
        output = output.view(output.size(0), -1)
        output = self.fc(output)

        return output


def resnet_18():
    return ResNet([2, 2, 2, 2])
