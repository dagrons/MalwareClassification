from bytes.create_data.generate_dataset import get_dataset
from bytes.resnet.resnet import resnet_18
from tensorboardX import SummaryWriter
from apex import amp

import torch.nn as nn
import torch
import torch.utils.data


def train_model(model_path, epoch):
    """
    Train the specified model.
    :param model_path: The path to save model.
    :param epoch: Number of iterations to train model.
    :return: Trained model.
    """
    train_path = input("Please input the path of training data: ")
    if train_path[-1] != '/':
        train_path += '/'
    test_path = input("Please input the path of test data: ")
    if test_path[-1] != '/':
        test_path += '/'

    writer = SummaryWriter(comment="ResNet")

    # get training Dataset
    dataset = get_dataset(train_path)
    # get training DataLoader
    train_loader = torch.utils.data.dataloader.DataLoader(dataset, batch_size=28, drop_last=True)

    # get test Dataset
    dataset = get_dataset(test_path)
    # get test DataLoader
    test_loader = torch.utils.data.dataloader.DataLoader(dataset, batch_size=64)

    criterion = nn.CrossEntropyLoss().cuda()

    model = resnet_18().cuda()

    # Kaiming He initialization
    for m in model.modules():
        if isinstance(m, (nn.Conv2d, nn.Linear)):
            nn.init.kaiming_normal_(m.weight, mode='fan_in')

    # the input of tensorboard
    temp = torch.rand(20, 3, 256, 256).cuda()

    writer.add_graph(model, (temp,))

    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)

    model, optimizer = amp.initialize(model, optimizer, opt_level="O1")

    best_accuracy = 0.0

    step = 0

    for i in range(epoch):
        print("epoch:", i)
        model.train()
        for j, data in enumerate(train_loader):
            x, y = data
            x = x.cuda()
            y = y.cuda()

            x_var = torch.autograd.Variable(x)
            y_var = torch.autograd.Variable(y.long())

            prediction = model(x_var)

            loss = criterion(prediction, y_var)

            optimizer.zero_grad()
            with amp.scale_loss(loss, optimizer) as scaled_loss:
                scaled_loss.backward()
            optimizer.step()

            # save loss and epoch
            writer.add_scalar("Loss", loss, step)
            step += 1

        print('--------Validation--------')
        correct = torch.zeros(1).squeeze().cuda()
        total = torch.zeros(1).squeeze().cuda()

        model.eval()
        with torch.no_grad():
            for j, data in enumerate(test_loader):
                x, y = data

                x = x.cuda()
                y = y.cuda()

                output = model(x)

                prediction = torch.argmax(output, 1)

                correct += (prediction == y.long()).sum().float()
                total += len(y)

            accuracy = (correct / total).cpu().item()
            writer.add_scalar("Accuracy", accuracy, i)
            if accuracy > best_accuracy:
                # save best model
                torch.save(model, "".join(model_path.split('.')[:-1]) + "_best.pth")
                best_accuracy = accuracy

    torch.save(model, model_path)

    writer.close()
