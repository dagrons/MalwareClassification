import os
import shutil
import pandas as pd
import torch.utils.data

from bytes.create_data.bytes2img import *


class MalwareData(torch.utils.data.Dataset):
    def __init__(self, x, y):
        self.x = x
        self.y = np.asarray(y)

    def __getitem__(self, item):
        x = self.x[item]
        y = self.y[item]

        x = torch.from_numpy(x)

        return x.float(), y

    def __len__(self):
        return len(self.x)


def split_dataset(src_path, dest_path, label_path):
    """
    Split all .bytes files into 9 categories, each category representing a family.
    :param src_path: The path of all .bytes files.
    :param dest_path: The path of 9 categories.
    :param label_path: The path of labels.csv.
    """
    # Read labels.csv
    df = pd.read_csv(label_path)

    if not os.path.exists(dest_path):
        os.mkdir(dest_path)
    # Split dataset into 9 categories
    for i in range(1, 10):

        filename_list = df.Id[df['Class'] == i].tolist()
        # Delete the same file names
        filename_list = list(set(filename_list))
        if not os.path.exists(dest_path + str(i)):
            os.mkdir(dest_path + str(i))
        for file_name in filename_list:
            shutil.move(src_path + file_name + '.bytes', dest_path + str(i) + '/' + file_name + '.bytes')

    os.rmdir(src_path)


def generate_train_test(bytes_path):
    """
    Split all .bytes files into training samples and test samples.
    :param bytes_path: The path of all .bytes files.
    """
    train_path = '/'.join(bytes_path.split('/')[:-1]) + "/train/"
    test_path = '/'.join(bytes_path.split('/')[:-1]) + "/test/"

    dirs = os.listdir(bytes_path)
    for dir in dirs:
        files = os.listdir(bytes_path + dir)

        num = len(files)
        train_num = int(num * 0.8)

        if not os.path.exists(train_path):
            os.mkdir(train_path)
        if not os.path.exists(test_path):
            os.mkdir(test_path)
        if not os.path.exists(train_path + dir):
            os.mkdir(train_path + dir)
        if not os.path.exists(test_path + dir):
            os.mkdir(test_path + dir)

        for bytes in files[0:train_num]:
            shutil.move(bytes_path + dir + '/' + bytes, train_path + dir + '/' + bytes)
        for bytes in files[train_num:]:
            shutil.move(bytes_path + dir + '/' + bytes, test_path + dir + '/' + bytes)

        os.rmdir(bytes_path + dir)


def get_dataset(bytes_path):
    """
    Get dataset from training path or test path.
    :param bytes_path: The path of .bytes files.
    :return: Training dataset or test dataset.
    """
    x = []
    y = []
    dirs = os.listdir(bytes_path)
    for dir in dirs:
        for bytes in os.listdir(bytes_path + dir):
            x.append(hex2mat(bytes_path + dir + '/' + bytes))
            y.append(int(dir) - 1)

    return MalwareData(x, y)


if __name__ == "__main__":
    # # Generate the Doc2Vec model
    # document_path = 'H:/malware/dataset/'
    # doc2vec_model_path = 'H:/malware/model/doc2vec.model'
    # vec_path = 'E:/malware/vec/'
    # my_doc2vec(document_path, doc2vec_model_path)
    # split_dataset('H:/malware/dataset/', 'H:/malware/data/', 'H:/malware/labels.csv')
    # vectorize_asm('H:/malware/data/', 'H:/malware/vec/', doc2vec_model_path)
    # generate_train_test(vec_path)
    dataset = get_dataset('E:/malware/vec/train/')
    print(dataset)
